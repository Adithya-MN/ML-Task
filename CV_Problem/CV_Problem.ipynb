{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV-Problem",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "h4Hg7kT1b9q4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ]
    },
    {
      "metadata": {
        "id": "1Ckf0SoMb8Go",
        "colab_type": "code",
        "outputId": "e5eac081-3f9b-41c5-c061-ee0c902708f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Standard data processing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#To unpickle the dataset\n",
        "import pickle\n",
        "\n",
        "#For gabage collection\n",
        "import gc\n",
        "\n",
        "#To visualize images and graphs\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#Using keras Sequential API to build a model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.layers import Layer\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,Flatten,Dense\n",
        "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import load_model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "anqts0Mlb87Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Colab File Handling"
      ]
    },
    {
      "metadata": {
        "id": "u0ROZnA3cGbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Mounting Google Drive and processing files (with workflow)"
      ]
    },
    {
      "metadata": {
        "id": "LJEix5i4ReTa",
        "colab_type": "code",
        "outputId": "967c83cd-0ecd-4427-cbd9-898277924c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Mounting google drive for file i/o\n",
        "from google.colab import drive\n",
        "while(True):\n",
        "    \n",
        "    # A try-catch loop fixes the issue of the mount timing out\n",
        "    try:\n",
        "        drive.mount('/content/gdrive')\n",
        "        break;\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oPyMA7_oce_6",
        "colab_type": "code",
        "outputId": "dc64fc01-33ed-4c58-bcf4-17a2de7e4e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Switching to the task directory\n",
        "cd gdrive/My\\ Drive/IIIT-D\\ Task/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/IIIT-D Task/'\n",
            "/content/gdrive/My Drive/IIIT-D Task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ORO8e18McMbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"Vision_task_dataset_public/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrouyfahcmT0",
        "colab_type": "code",
        "outputId": "43e08032-e033-45ed-facb-da83f9b9e9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls Vision_task_dataset_public/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'hitkul(sample_submission).csv'   train_image.pkl\n",
            " test_image.pkl\t\t\t  train_label.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CoMppq_qcnEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Unpickling and loading the files\n",
        "with open(PATH + 'train_image.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "    \n",
        "with open(PATH + 'test_image.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "    \n",
        "with open(PATH + 'train_label.pkl', 'rb') as f:\n",
        "    train_label = pickle.load(f)\n",
        "    \n",
        "sample_submission = pd.read_csv(PATH + \"hitkul(sample_submission).csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4gyyIckmhymb",
        "colab_type": "code",
        "outputId": "486c3371-d6f5-4055-aaae-af2e5ccffbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "#Figuring out the type and size of data\n",
        "print(type(train_data))\n",
        "print(type(train_data[0]))\n",
        "print(type(train_label))\n",
        "print(train_data.__len__())\n",
        "print(train_data[0].__len__())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "8000\n",
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TqNVv4lDNp3e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The images have shape 784, suggestiing they are 28*28 images"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "g8agk0AUikUN",
        "outputId": "cc3422ec-5626-43bc-86d8-342208d02894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Convert list to numpy array so that it can be passed to model\n",
        "train_data = np.array(train_data)\n",
        "test_data = np.array(test_data)\n",
        "train_label = np.array(train_label)\n",
        "#Reshaping to 28*28 with 1 channel for cnn operations\n",
        "train_data = train_data.reshape([-1,28,28,1])\n",
        "test_data = test_data.reshape([-1,28,28,1])\n",
        "#Conversion to float32 is memory efficent and hardly affects accuracy\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 28, 28, 1)\n",
            "(2000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eTWlFy7NtNt5",
        "colab_type": "code",
        "outputId": "17462436-3754-4d24-c2b3-3d5485aab416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Figuring out label value to encode to one hot\n",
        "np.unique(train_label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 3, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "Bn4OIQw1twEH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#onverting to one hot encodable\n",
        "train_label[train_label == 2] = 1\n",
        "train_label[train_label == 3] = 2\n",
        "train_label[train_label == 6] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jjoagnxg8MiS",
        "colab_type": "code",
        "outputId": "0e4f5a18-d677-49db-f800-6a1b4d08fde3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.unique(train_label)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "ETKvmj2HsmHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#encoding, finally!\n",
        "number_of_classes = 4\n",
        "\n",
        "train_label = np_utils.to_categorical(train_label, number_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ripAYs6085pi",
        "colab_type": "code",
        "outputId": "fa1dadd6-9f9c-40de-be38-bebf2450106f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_label.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "UN7XehQHpsPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_data,validation_data,training_label,validation_label = train_test_split(train_data,train_label, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UG30NLjgbxA7",
        "colab_type": "code",
        "outputId": "a04eabb5-ae21-4170-cb67-90954f080156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "validation_label[0:5,:]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "gvtkbl7agh08",
        "colab_type": "code",
        "outputId": "84fc8dad-e824-49f6-a134-5d966a277d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(4,4, figsize=(6, 6))\n",
        "for index in range(16):\n",
        "    ax[int(index/4),index%4].imshow(train_data[index,:,:,0])\n",
        "f.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFpCAYAAACBNaNRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKxBalUvlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9EX3exCucHEv",
        "colab_type": "code",
        "outputId": "a0b5d499-0ec5-4fb3-be13-6a80646ad80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "fTLIrAjmPFSW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training setup"
      ]
    },
    {
      "metadata": {
        "id": "W8z0ZQ6TkxEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fixing vales that'll be used commonly\n",
        "NUM_TRAIN = train_data.shape[0]\n",
        "TRAIN_SIZE = training_data.shape[0]\n",
        "VALIDATE_SIZE = validation_data.shape[0]\n",
        "IMAGE_SHAPE = train_data.shape[1:4]\n",
        "BATCH_SIZE = 12\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNLKhodSoVxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Setting up the generators, with data augmentation for training to help as dataset is small\n",
        "train_datagen = ImageDataGenerator(\n",
        "    #rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    #shear_range=0.1,\n",
        "    #zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(training_data,training_label,batch_size = BATCH_SIZE)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow(validation_data, validation_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4P-eouoWIes",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Attempt 1 "
      ]
    },
    {
      "metadata": {
        "id": "ypNOF78kPPdJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##An attempt using a shallow net first to classify (This is used for prediction finally)"
      ]
    },
    {
      "metadata": {
        "id": "C3rn4w3agwWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier = Sequential()\n",
        "Classifier.add(Conv2D(filters = 16, kernel_size = (3,3), input_shape = IMAGE_SHAPE, activation = 'relu'))\n",
        "Classifier.add(BatchNormalization(axis=-1))\n",
        "Classifier.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
        "Classifier.add(BatchNormalization(axis=-1))\n",
        "Classifier.add(MaxPooling2D((2,2), strides = 2))\n",
        "Classifier.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n",
        "Classifier.add(MaxPooling2D((2,2), strides = 2))\n",
        "Classifier.add(Flatten())\n",
        "Classifier.add(Dense(256, activation = 'relu'))\n",
        "Classifier.add(Dropout(0.2))\n",
        "Classifier.add(Dense(4, activation = 'softmax'))\n",
        "Classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2bQF--rmOav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier.compile(loss='categorical_crossentropy',optimizer=optimizers.adam(lr=1e-4),metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpku2YnjhvuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "cb64da8c-7ec8-4d7b-b403-eef5021650f7"
      },
      "cell_type": "code",
      "source": [
        "Classifier = load_model(\"shallow_model.h5\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uibpZu_29G8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Callbacks to help training\n",
        "earlystop = EarlyStopping(patience=70)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "mc = ModelCheckpoint(\n",
        "        \"shallow_model.h5\",\n",
        "        monitor='val_acc',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1)\n",
        "callbacks = [earlystop, learning_rate_reduction,mc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wSpyjVbJfEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "7j-g3fN1ZNnN",
        "colab_type": "code",
        "outputId": "2d147c08-aae5-4f85-84ee-115aa773b151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8449
        }
      },
      "cell_type": "code",
      "source": [
        "epochs=1000\n",
        "history = Classifier.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=VALIDATE_SIZE//BATCH_SIZE,\n",
        "    steps_per_epoch=TRAIN_SIZE//BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "Classifier.save(\"s_model.g5\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.3097 - acc: 0.8800 - val_loss: 0.3294 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.85417, saving model to shallow_model.h5\n",
            "Epoch 2/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3453 - acc: 0.8967 - val_loss: 0.5303 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.85417\n",
            "Epoch 3/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3059 - acc: 0.8633 - val_loss: 0.3541 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.85417 to 0.87500, saving model to shallow_model.h5\n",
            "Epoch 4/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3087 - acc: 0.8867 - val_loss: 0.3802 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87500\n",
            "Epoch 5/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3603 - acc: 0.8367 - val_loss: 0.3779 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87500\n",
            "Epoch 6/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3900 - acc: 0.8600 - val_loss: 0.3669 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87500\n",
            "Epoch 7/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3450 - acc: 0.8733 - val_loss: 0.3721 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87500\n",
            "Epoch 8/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3935 - acc: 0.8367 - val_loss: 0.5025 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87500\n",
            "Epoch 9/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3783 - acc: 0.8367 - val_loss: 0.4276 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87500\n",
            "Epoch 10/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3963 - acc: 0.8467 - val_loss: 0.4384 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87500\n",
            "Epoch 11/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3643 - acc: 0.8600 - val_loss: 0.3943 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.87500\n",
            "Epoch 12/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4026 - acc: 0.8467 - val_loss: 0.4494 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.87500\n",
            "Epoch 13/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3644 - acc: 0.8500 - val_loss: 0.3947 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.87500\n",
            "Epoch 14/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3405 - acc: 0.8633 - val_loss: 0.3781 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.87500\n",
            "Epoch 15/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3405 - acc: 0.8767 - val_loss: 0.3416 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.87500\n",
            "Epoch 16/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3116 - acc: 0.8767 - val_loss: 0.3937 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.87500\n",
            "Epoch 17/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3973 - acc: 0.8467 - val_loss: 0.3851 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.87500\n",
            "Epoch 18/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4334 - acc: 0.8300 - val_loss: 0.3041 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.87500\n",
            "Epoch 19/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4340 - acc: 0.7967 - val_loss: 0.3797 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.87500\n",
            "Epoch 20/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.2952 - acc: 0.8800 - val_loss: 0.3388 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.87500\n",
            "Epoch 21/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3777 - acc: 0.8433 - val_loss: 0.3517 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.87500\n",
            "Epoch 22/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3993 - acc: 0.8098 - val_loss: 0.3843 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.87500\n",
            "Epoch 23/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4237 - acc: 0.8467 - val_loss: 0.4260 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.87500\n",
            "Epoch 24/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3135 - acc: 0.8667 - val_loss: 0.5545 - val_acc: 0.7656\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.87500\n",
            "Epoch 25/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3549 - acc: 0.8800 - val_loss: 0.4689 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.87500\n",
            "Epoch 26/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3269 - acc: 0.8900 - val_loss: 0.5129 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.87500\n",
            "Epoch 27/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3261 - acc: 0.8433 - val_loss: 0.4006 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.87500\n",
            "Epoch 28/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3858 - acc: 0.8533 - val_loss: 0.4178 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.87500\n",
            "Epoch 29/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3477 - acc: 0.8633 - val_loss: 0.3665 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.87500\n",
            "Epoch 30/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3364 - acc: 0.8633 - val_loss: 0.4029 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.87500\n",
            "Epoch 31/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3912 - acc: 0.8233 - val_loss: 0.3796 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.87500\n",
            "Epoch 32/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3699 - acc: 0.8567 - val_loss: 0.3831 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.87500\n",
            "Epoch 33/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4199 - acc: 0.8500 - val_loss: 0.3683 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.87500\n",
            "Epoch 34/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.2905 - acc: 0.8767 - val_loss: 0.4459 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.87500\n",
            "Epoch 35/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3788 - acc: 0.8567 - val_loss: 0.3652 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.87500\n",
            "Epoch 36/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3498 - acc: 0.8700 - val_loss: 0.3809 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.87500\n",
            "Epoch 37/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3467 - acc: 0.8600 - val_loss: 0.4568 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.87500\n",
            "Epoch 38/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3797 - acc: 0.8567 - val_loss: 0.3639 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.87500\n",
            "Epoch 39/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3845 - acc: 0.8600 - val_loss: 0.4050 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.87500\n",
            "Epoch 40/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3147 - acc: 0.8733 - val_loss: 0.3305 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.87500\n",
            "Epoch 41/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3950 - acc: 0.8433 - val_loss: 0.4190 - val_acc: 0.8073\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.87500\n",
            "Epoch 42/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3098 - acc: 0.8767 - val_loss: 0.4549 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.87500\n",
            "Epoch 43/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3366 - acc: 0.8668 - val_loss: 0.4772 - val_acc: 0.7708\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.87500\n",
            "Epoch 44/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3796 - acc: 0.8533 - val_loss: 0.4715 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.87500\n",
            "Epoch 45/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3585 - acc: 0.8467 - val_loss: 0.3556 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.87500\n",
            "Epoch 46/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3562 - acc: 0.8567 - val_loss: 0.4514 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.87500\n",
            "Epoch 47/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4038 - acc: 0.8467 - val_loss: 0.3638 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.87500\n",
            "Epoch 48/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3658 - acc: 0.8567 - val_loss: 0.3364 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.87500\n",
            "Epoch 49/1000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.3640 - acc: 0.8700 - val_loss: 0.3054 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.87500\n",
            "Epoch 50/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4192 - acc: 0.8433 - val_loss: 0.3552 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.87500\n",
            "Epoch 51/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.2596 - acc: 0.8967 - val_loss: 0.4827 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.87500\n",
            "Epoch 52/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.2975 - acc: 0.8800 - val_loss: 0.3744 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.87500\n",
            "Epoch 53/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3333 - acc: 0.8433 - val_loss: 0.4451 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.87500\n",
            "Epoch 54/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4731 - acc: 0.8333 - val_loss: 0.2669 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00054: val_acc improved from 0.87500 to 0.90104, saving model to shallow_model.h5\n",
            "Epoch 55/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3423 - acc: 0.8667 - val_loss: 0.4612 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.90104\n",
            "Epoch 56/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3287 - acc: 0.8700 - val_loss: 0.4108 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.90104\n",
            "Epoch 57/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3030 - acc: 0.8767 - val_loss: 0.3783 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.90104\n",
            "Epoch 58/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.2678 - acc: 0.9000 - val_loss: 0.3749 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.90104\n",
            "Epoch 59/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3131 - acc: 0.8800 - val_loss: 0.4322 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.90104\n",
            "Epoch 60/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3806 - acc: 0.8600 - val_loss: 0.3587 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.90104\n",
            "Epoch 61/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4610 - acc: 0.8300 - val_loss: 0.4304 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.90104\n",
            "Epoch 62/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3789 - acc: 0.8500 - val_loss: 0.5227 - val_acc: 0.8073\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.90104\n",
            "Epoch 63/1000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.3717 - acc: 0.8600 - val_loss: 0.3739 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.90104\n",
            "Epoch 64/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3658 - acc: 0.8633 - val_loss: 0.4200 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.90104\n",
            "Epoch 65/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3577 - acc: 0.8601 - val_loss: 0.3001 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.90104\n",
            "Epoch 66/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3328 - acc: 0.8700 - val_loss: 0.3440 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.90104\n",
            "Epoch 67/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4055 - acc: 0.8467 - val_loss: 0.3831 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.90104\n",
            "Epoch 68/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3606 - acc: 0.8533 - val_loss: 0.4225 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.90104\n",
            "Epoch 69/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3906 - acc: 0.8567 - val_loss: 0.4257 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.90104\n",
            "Epoch 70/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3978 - acc: 0.8167 - val_loss: 0.3464 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.90104\n",
            "Epoch 71/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3782 - acc: 0.8633 - val_loss: 0.4524 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.90104\n",
            "Epoch 72/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3846 - acc: 0.8600 - val_loss: 0.3033 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.90104\n",
            "Epoch 73/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3651 - acc: 0.8533 - val_loss: 0.4462 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.90104\n",
            "Epoch 74/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3798 - acc: 0.8467 - val_loss: 0.3372 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.90104\n",
            "Epoch 75/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3539 - acc: 0.8500 - val_loss: 0.4144 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.90104\n",
            "Epoch 76/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3492 - acc: 0.8500 - val_loss: 0.3228 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.90104\n",
            "Epoch 77/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4404 - acc: 0.8167 - val_loss: 0.4977 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.90104\n",
            "Epoch 78/1000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3087 - acc: 0.8767 - val_loss: 0.2732 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.90104\n",
            "Epoch 79/1000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3219 - acc: 0.8633 - val_loss: 0.3836 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.90104\n",
            "Epoch 80/1000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3473 - acc: 0.8533 - val_loss: 0.3419 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.90104\n",
            "Epoch 81/1000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.3725 - acc: 0.8600 - val_loss: 0.3319 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.90104\n",
            "Epoch 82/1000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3914 - acc: 0.8467 - val_loss: 0.4165 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.90104\n",
            "Epoch 83/1000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3607 - acc: 0.8400 - val_loss: 0.4983 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.90104\n",
            "Epoch 84/1000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3245 - acc: 0.8867 - val_loss: 0.4525 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.90104\n",
            "Epoch 85/1000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3313 - acc: 0.8667 - val_loss: 0.3861 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.90104\n",
            "Epoch 86/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3360 - acc: 0.8635 - val_loss: 0.3489 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.90104\n",
            "Epoch 87/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4136 - acc: 0.8533 - val_loss: 0.4654 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.90104\n",
            "Epoch 88/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3472 - acc: 0.8567 - val_loss: 0.4060 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.90104\n",
            "Epoch 89/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3901 - acc: 0.8400 - val_loss: 0.4084 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.90104\n",
            "Epoch 90/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4123 - acc: 0.8467 - val_loss: 0.3748 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.90104\n",
            "Epoch 91/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4029 - acc: 0.8433 - val_loss: 0.3640 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.90104\n",
            "Epoch 92/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3735 - acc: 0.8467 - val_loss: 0.4139 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.90104\n",
            "Epoch 93/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3948 - acc: 0.8467 - val_loss: 0.3041 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.90104\n",
            "Epoch 94/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3557 - acc: 0.8500 - val_loss: 0.4866 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.90104\n",
            "Epoch 95/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3023 - acc: 0.8767 - val_loss: 0.4074 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.90104\n",
            "Epoch 96/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3496 - acc: 0.8633 - val_loss: 0.4210 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.90104\n",
            "Epoch 97/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3684 - acc: 0.8633 - val_loss: 0.3462 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.90104\n",
            "Epoch 98/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4155 - acc: 0.8200 - val_loss: 0.3136 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.90104\n",
            "Epoch 99/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3953 - acc: 0.8500 - val_loss: 0.4357 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.90104\n",
            "Epoch 100/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4179 - acc: 0.8400 - val_loss: 0.3461 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.90104\n",
            "Epoch 101/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3903 - acc: 0.8367 - val_loss: 0.3237 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.90104\n",
            "Epoch 102/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3051 - acc: 0.8867 - val_loss: 0.3380 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.90104\n",
            "Epoch 103/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3268 - acc: 0.8600 - val_loss: 0.3845 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.90104\n",
            "Epoch 104/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3815 - acc: 0.8767 - val_loss: 0.3816 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.90104\n",
            "Epoch 105/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3091 - acc: 0.8600 - val_loss: 0.5225 - val_acc: 0.8073\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.90104\n",
            "Epoch 106/1000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3241 - acc: 0.8700 - val_loss: 0.3561 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.90104\n",
            "Epoch 107/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3340 - acc: 0.8568 - val_loss: 0.2765 - val_acc: 0.8906\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.90104\n",
            "Epoch 108/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3290 - acc: 0.8467 - val_loss: 0.4399 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.90104\n",
            "Epoch 109/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3249 - acc: 0.8800 - val_loss: 0.5841 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.90104\n",
            "Epoch 110/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3764 - acc: 0.8300 - val_loss: 0.3591 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.90104\n",
            "Epoch 111/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3607 - acc: 0.8933 - val_loss: 0.4075 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.90104\n",
            "Epoch 112/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3947 - acc: 0.8367 - val_loss: 0.3985 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.90104\n",
            "Epoch 113/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4205 - acc: 0.8500 - val_loss: 0.3845 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.90104\n",
            "Epoch 114/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3845 - acc: 0.8533 - val_loss: 0.4109 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.90104\n",
            "Epoch 115/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4689 - acc: 0.8133 - val_loss: 0.3247 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.90104\n",
            "Epoch 116/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3239 - acc: 0.8567 - val_loss: 0.3662 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.90104\n",
            "Epoch 117/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3225 - acc: 0.8800 - val_loss: 0.4343 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.90104\n",
            "Epoch 118/1000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4338 - acc: 0.8300 - val_loss: 0.5049 - val_acc: 0.8073\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.90104\n",
            "Epoch 119/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3653 - acc: 0.8733 - val_loss: 0.3289 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.90104\n",
            "Epoch 120/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3349 - acc: 0.8733 - val_loss: 0.3211 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.90104\n",
            "Epoch 121/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.2908 - acc: 0.8933 - val_loss: 0.3979 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.90104\n",
            "Epoch 122/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3578 - acc: 0.8367 - val_loss: 0.3291 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.90104\n",
            "Epoch 123/1000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.2979 - acc: 0.8933 - val_loss: 0.4030 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.90104\n",
            "Epoch 124/1000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.2978 - acc: 0.9033 - val_loss: 0.4241 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.90104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qT-EoxNzSrpo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier = load_model(\"shallow_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xu3sRiGMXRNx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction = Classifier.predict(test_data)\n",
        "prediction = np.argmax(prediction, axis = 1)\n",
        "prediction[prediction == 1] = 2\n",
        "prediction[prediction == 2] = 3\n",
        "prediction[prediction == 3] = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a3eca532-2444-4d01-efd0-df14058ec768",
        "id": "_etzQwlxjgX8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'image_index': list(np.arange(len(prediction))) ,'class': prediction})\n",
        "df = df[['image_index', 'class']]\n",
        "df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_index</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_index  class\n",
              "0            0      6\n",
              "1            1      6\n",
              "2            2      6\n",
              "3            3      0\n",
              "4            4      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "VCU5uTCCj2B3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv('test_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M9rKFmv1L5TJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('test_submission.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8e_WtNkXRuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Attempt 2"
      ]
    },
    {
      "metadata": {
        "id": "Ss4zDa6Yd43k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model definition"
      ]
    },
    {
      "metadata": {
        "id": "HMl1BwLVbHuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Building the VGG model for 1D data\n",
        "def VGG1D():\n",
        "    input_tensor=Input(shape=(IMAGE_SHAPE))\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_tensor)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Classification block\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4, activation='softmax', name='predictions')(x)\n",
        "    return Model(inputs=[input_tensor],outputs=[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkCiwGP0OoE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier = VGG1D()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QV6KWl4ajrg",
        "colab_type": "code",
        "outputId": "1c03a639-12c2-4531-fd7e-0d2dff301439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "cell_type": "code",
      "source": [
        "Classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 3, 3, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 26,533,060\n",
            "Trainable params: 26,533,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "92C2d7myd7Ex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier.compile(loss='categorical_crossentropy',optimizer=optimizers.sgd(),metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtluvEd2d9C6",
        "colab_type": "code",
        "outputId": "be138d90-5503-4f2c-8077-623076b18c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier_model.h5  s_model.g5\t\t   transfer_model.h5\n",
            "deep_model.h5\t     test_submission2.csv  Vision_task_dataset_public\n",
            "model.g5\t     test_submission.csv\n",
            "shallow_model.h5     t_model.g5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pQ-GLe62d9l5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model Training"
      ]
    },
    {
      "metadata": {
        "id": "ZhKOjsNjeBK9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Classifier = load_model(\"deep_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KBOBlSWakwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(patience=25)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "mc = ModelCheckpoint(\n",
        "        \"deep_model.h5\",\n",
        "        monitor='val_acc',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1)\n",
        "callbacks = [earlystop, learning_rate_reduction,mc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EN-zRTIL1NzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ReLr79Yfak2f",
        "colab_type": "code",
        "outputId": "b6a8b9d8-9b76-44b2-e75c-872fcb8f0a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "history = Classifier.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=VALIDATE_SIZE//BATCH_SIZE,\n",
        "    steps_per_epoch=TRAIN_SIZE//BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "#Classifier.save(\"d_model.g5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 91s 912ms/step - loss: 0.6089 - acc: 0.7417 - val_loss: 0.5650 - val_acc: 0.7475\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.77750\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 91s 908ms/step - loss: 0.6405 - acc: 0.7283 - val_loss: 0.6091 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.77750\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 92s 921ms/step - loss: 0.6131 - acc: 0.7350 - val_loss: 0.6537 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.77750\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 91s 908ms/step - loss: 0.5877 - acc: 0.7675 - val_loss: 0.5015 - val_acc: 0.7812\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77750 to 0.78125, saving model to deep_model.h5\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 92s 923ms/step - loss: 0.6209 - acc: 0.7458 - val_loss: 0.5922 - val_acc: 0.7475\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.78125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QmQzdyMFqzdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction = Classifier.predict(test_data)\n",
        "prediction = np.argmax(prediction, axis = 1)\n",
        "prediction[prediction == 1] = 2\n",
        "prediction[prediction == 2] = 3\n",
        "prediction[prediction == 3] = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5yaLc0vstDPM",
        "colab_type": "code",
        "outputId": "b8d1aecc-80c8-4142-c3c7-e7d62e2cf8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "prediction.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "VLtVpviFrVkF",
        "colab_type": "code",
        "outputId": "3b1027cd-b75f-4fb8-f426-b757497fab88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'image_index': list(np.arange(len(prediction))) ,'class': prediction})\n",
        "df = df[['image_index', 'class']]\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>image_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class  image_index\n",
              "0      0            0\n",
              "1      0            1\n",
              "2      0            2\n",
              "3      0            3\n",
              "4      0            4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "TpJpLXlwrwak",
        "colab_type": "code",
        "outputId": "3a09f105-1084-4cc9-949b-9659787439be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "sample_submission"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_index</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_index  class\n",
              "0            0      2\n",
              "1            1      3\n",
              "2            2      0\n",
              "3            3      6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "MJ2M7yzitwsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv('test_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}